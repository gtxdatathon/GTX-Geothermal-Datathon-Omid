{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5681047a-9e32-433f-b5f2-a6a8d05a7734",
   "metadata": {},
   "source": [
    "# Installing PyTorch\n",
    "## Here, is the process to install and configure PyTorch\n",
    "\n",
    "## First, check your systems specifications:\n",
    " 1. Are you running Windows, Linux, or MacOS as your operating system ?\n",
    " 2. If you are running on Linux Check your distribution and release informaion\n",
    " 3. Is your system equiped with Graphical Processing Units (GPUs)?\n",
    " 4. Go to https://pytorch.org/ and install the right version of PyTorch specific to your needs\n",
    " \n",
    "## This notebook is following and borrows from\n",
    "###### https://youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dec6cf9-e7eb-46ea-bbef-68ddeb4e4756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIB_ID=Ubuntu\n",
      "DISTRIB_RELEASE=18.04\n",
      "DISTRIB_CODENAME=bionic\n",
      "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.3 LTS\"\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/lsb-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120ab356-2e9f-4916-86fb-1bad0965b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 18 18:12:00 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Tesla V1...  Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   30C    P0    24W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA Tesla V1...  Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   32C    P0    25W / 250W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0deb4dbe-294f-4fc5-a7f9-f160f658f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.8.1+cu111\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d01741-eeab-488d-bcce-cb7ebf92081d",
   "metadata": {},
   "source": [
    "# Check the Successful Installation of PyTorch & working with GPUs\n",
    "\n",
    "### Import torch and check the installed version of torch with __version__\n",
    "### Check whether torch can see the installed GPU this is only in case that you have GPUs installed with proper libraries either Nvidia CUDA or AMD ROCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23cca41-fd06-4a30-9042-aab77739f257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu111'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ee19b4-2b61-4c22-ab03-8a437fd41c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0055149f-b6fc-4407-95dd-ddcebd369795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 17 23:52:27 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Tesla V1...  Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   30C    P0    24W / 250W |      4MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA Tesla V1...  Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   32C    P0    25W / 250W |      4MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d4ebe7-3916-4d57-83eb-30a66dec81bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.can_device_access_peer(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b310b9f-9fa3-47a0-a5f8-869e2184be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc2d39c8-e913-4467-95aa-af028b0a8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA Tesla V100-PCIE-16GB'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfc742d-430a-4a9a-9cdf-5ccbcfe094c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA Tesla V100-PCIE-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd5ebf-a59d-46c0-a7dd-2654f28ac68b",
   "metadata": {},
   "source": [
    "## These are some simple CUDA GPU APIs from Torch\n",
    "### for more please check out https://pytorch.org/docs/stable/cuda.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
